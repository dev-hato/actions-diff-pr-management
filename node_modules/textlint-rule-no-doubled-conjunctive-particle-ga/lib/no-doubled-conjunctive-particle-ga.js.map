{"version":3,"sources":["../src/no-doubled-conjunctive-particle-ga.js"],"names":["defaultOptions","separatorChars","context","options","helper","RuleHelper","Syntax","report","getSource","RuleError","Paragraph","node","isChildNode","Link","Image","BlockQuote","Emphasis","isSentenceNode","type","SentenceSyntax","Sentence","sentences","SeparatorParser","separatorCharacters","children","filter","source","StringSource","then","tokenizer","checkSentence","sentence","sentenceText","tokens","tokenizeForSentence","isConjunctiveParticleGaToken","token","pos_detail_1","surface_form","conjunctiveParticleGaTokens","length","current","sentenceIndex","originalIndexFromPosition","loc","start","currentIndex","word_position","index","forEach"],"mappings":"AAAA;AACA;;;;;;;AACA;;AACA;;AACA;;AACA;;AAEA,IAAMA,cAAc,GAAG;AACnBC,EAAAA,cAAc,EAAE,CACZ,GADY,EACP;AACL,KAFY,EAEP;AACL,KAHY,EAGP;AACL,KAJY,EAIP;AACL,KALY,EAKP;AACL,KANY,EAMP;AACL,KAPY,CAOR;AAPQ;AADG,CAAvB;AAWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACe,kBAAUC,OAAV,EAAiC;AAAA;;AAAA,MAAdC,OAAc,uEAAJ,EAAI;AAC5C,MAAMF,cAAc,4BAAGE,OAAO,CAACF,cAAX,yEAA6BD,cAAc,CAACC,cAAhE;AACA,MAAMG,MAAM,GAAG,IAAIC,8BAAJ,CAAeH,OAAf,CAAf;AACA,MAAM;AAAEI,IAAAA,MAAF;AAAUC,IAAAA,MAAV;AAAkBC,IAAAA,SAAlB;AAA6BC,IAAAA;AAA7B,MAA2CP,OAAjD;AACA,SAAO;AACH,KAACI,MAAM,CAACI,SAAR,EAAmBC,IAAnB,EAAyB;AACrB,UAAIP,MAAM,CAACQ,WAAP,CAAmBD,IAAnB,EAAyB,CAACL,MAAM,CAACO,IAAR,EAAcP,MAAM,CAACQ,KAArB,EAA4BR,MAAM,CAACS,UAAnC,EAA+CT,MAAM,CAACU,QAAtD,CAAzB,CAAJ,EAA+F;AAC3F;AACH;;AACD,UAAMC,cAAc,GAAGN,IAAI,IAAI;AAC3B,eAAOA,IAAI,CAACO,IAAL,KAAcC,yBAAeC,QAApC;AACH,OAFD;;AAGA,UAAMC,SAAS,GAAG,gCAASV,IAAT,EAAe;AAC7BW,QAAAA,eAAe,EAAE;AACbC,UAAAA,mBAAmB,EAAEtB;AADR;AADY,OAAf,EAIfuB,QAJe,CAINC,MAJM,CAICR,cAJD,CAAlB;AAKA,UAAMS,MAAM,GAAG,IAAIC,kCAAJ,CAAiBhB,IAAjB,CAAf;AACA,aAAO,+BAAeiB,IAAf,CAAoBC,SAAS,IAAI;AACpC,YAAMC,aAAa,GAAIC,QAAD,IAAc;AAChC,cAAMC,YAAY,GAAGxB,SAAS,CAACuB,QAAD,CAA9B;AACA,cAAME,MAAM,GAAGJ,SAAS,CAACK,mBAAV,CAA8BF,YAA9B,CAAf;;AACA,cAAMG,4BAA4B,GAAGC,KAAK,IAAI;AAC1C,mBAAOA,KAAK,CAACC,YAAN,KAAuB,MAAvB,IAAiCD,KAAK,CAACE,YAAN,KAAuB,GAA/D;AACH,WAFD;;AAGA,cAAMC,2BAA2B,GAAGN,MAAM,CAACR,MAAP,CAAcU,4BAAd,CAApC;;AACA,cAAII,2BAA2B,CAACC,MAA5B,IAAsC,CAA1C,EAA6C;AACzC;AACH;;AACD,cAAMC,OAAO,GAAGF,2BAA2B,CAAC,CAAD,CAA3C;AACA,cAAMG,aAAa,GAAGhB,MAAM,CAACiB,yBAAP,CAAiCZ,QAAQ,CAACa,GAAT,CAAaC,KAA9C,KAAwD,CAA9E;AACA,cAAMC,YAAY,GAAGJ,aAAa,IAAID,OAAO,CAACM,aAAR,GAAwB,CAA5B,CAAlC;AACAxC,UAAAA,MAAM,CAACI,IAAD,EAAO,IAAIF,SAAJ,2JAA8C;AACvDuC,YAAAA,KAAK,EAAEF;AADgD,WAA9C,CAAP,CAAN;AAGA,iBAAOL,OAAP;AACH,SAjBD;;AAkBApB,QAAAA,SAAS,CAAC4B,OAAV,CAAkBnB,aAAlB;AACH,OApBM,CAAP;AAqBH;;AAnCE,GAAP;AAqCH;;AAAA","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport { RuleHelper } from \"textlint-rule-helper\";\nimport { getTokenizer } from \"kuromojin\";\nimport { splitAST, Syntax as SentenceSyntax } from \"sentence-splitter\";\nimport { StringSource } from \"textlint-util-to-string\";\n\nconst defaultOptions = {\n    separatorChars: [\n        \".\", // period\n        \"．\", // (ja) zenkaku-period\n        \"。\", // (ja) 句点\n        \"?\", // question mark\n        \"!\", //  exclamation mark\n        \"？\", // (ja) zenkaku question mark\n        \"！\" // (ja) zenkaku exclamation mark\n    ]\n};\n/*\n    1. Paragraph Node -> text\n    2. text -> sentences\n    3. tokenize sentence\n    4. report error if found word that match the rule.\n\n    TODO: need abstraction\n */\nexport default function (context, options = {}) {\n    const separatorChars = options.separatorChars ?? defaultOptions.separatorChars;\n    const helper = new RuleHelper(context);\n    const { Syntax, report, getSource, RuleError } = context;\n    return {\n        [Syntax.Paragraph](node) {\n            if (helper.isChildNode(node, [Syntax.Link, Syntax.Image, Syntax.BlockQuote, Syntax.Emphasis])) {\n                return;\n            }\n            const isSentenceNode = node => {\n                return node.type === SentenceSyntax.Sentence;\n            };\n            const sentences = splitAST(node, {\n                SeparatorParser: {\n                    separatorCharacters: separatorChars\n                }\n            }).children.filter(isSentenceNode);\n            const source = new StringSource(node);\n            return getTokenizer().then(tokenizer => {\n                const checkSentence = (sentence) => {\n                    const sentenceText = getSource(sentence);\n                    const tokens = tokenizer.tokenizeForSentence(sentenceText);\n                    const isConjunctiveParticleGaToken = token => {\n                        return token.pos_detail_1 === \"接続助詞\" && token.surface_form === \"が\";\n                    };\n                    const conjunctiveParticleGaTokens = tokens.filter(isConjunctiveParticleGaToken);\n                    if (conjunctiveParticleGaTokens.length <= 1) {\n                        return;\n                    }\n                    const current = conjunctiveParticleGaTokens[0];\n                    const sentenceIndex = source.originalIndexFromPosition(sentence.loc.start) || 0;\n                    const currentIndex = sentenceIndex + (current.word_position - 1);\n                    report(node, new RuleError(`文中に逆接の接続助詞 \"が\" が二回以上使われています。`, {\n                        index: currentIndex\n                    }));\n                    return current;\n                }\n                sentences.forEach(checkSentence);\n            });\n        }\n    }\n};\n"],"file":"no-doubled-conjunctive-particle-ga.js"}