// LICENSE : MIT
"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = _default;

var _textlintRuleHelper = require("textlint-rule-helper");

var _kuromojin = require("kuromojin");

var _sentenceSplitter = require("sentence-splitter");

var _textlintUtilToString = require("textlint-util-to-string");

/*
    1. Paragraph Node -> text
    2. text -> sentences
    3. tokenize sentence
    4. report error if found word that match the rule.

    TODO: need abstraction
 */
function _default(context) {
  var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  var helper = new _textlintRuleHelper.RuleHelper(context);
  var {
    Syntax,
    report,
    getSource,
    RuleError
  } = context;
  return {
    [Syntax.Paragraph](node) {
      if (helper.isChildNode(node, [Syntax.Link, Syntax.Image, Syntax.BlockQuote, Syntax.Emphasis])) {
        return;
      }

      var source = new _textlintUtilToString.StringSource(node);
      var text = source.toString();

      var isSentenceNode = node => node.type === _sentenceSplitter.Syntax.Sentence;

      var sentences = (0, _sentenceSplitter.split)(text, {
        SeparatorParser: {
          separatorCharacters: [".", // period
          "．", // (ja) zenkaku-period
          "。", // (ja) 句点
          "?", // question mark
          "!", //  exclamation mark
          "？", // (ja) zenkaku question mark
          "！" // (ja) zenkaku exclamation mark
          ]
        }
      }).filter(isSentenceNode); // if not have a sentence, early return
      // It is for avoiding error of emptyArray.reduce().

      if (sentences.length === 0) {
        return;
      }

      return (0, _kuromojin.getTokenizer)().then(tokenizer => {
        var selectConjenction = sentence => {
          var tokens = tokenizer.tokenizeForSentence(sentence.raw);
          var conjunctionTokens = tokens.filter(token => token.pos === "接続詞");
          return [sentence, conjunctionTokens];
        };

        var prev_token = null;
        sentences.map(selectConjenction).reduce((prev, current) => {
          var [sentence, current_tokens] = current;
          var [prev_sentence, prev_tokens] = prev;
          var token = prev_token;

          if (prev_tokens && prev_tokens.length > 0) {
            token = prev_tokens[0];
          }

          if (current_tokens.length > 0) {
            if (token && current_tokens[0].surface_form === token.surface_form) {
              var conjunctionSurface = token.surface_form;
              var originalIndex = source.originalIndexFromPosition({
                line: sentence.loc.start.line,
                column: sentence.loc.start.column + (current_tokens[0].word_position - 1)
              }); // padding position

              var padding = {
                index: originalIndex
              };
              report(node, new RuleError("\u540C\u3058\u63A5\u7D9A\u8A5E\uFF08".concat(conjunctionSurface, "\uFF09\u304C\u9023\u7D9A\u3057\u3066\u4F7F\u308F\u308C\u3066\u3044\u307E\u3059\u3002"), padding));
            }
          }

          prev_token = token;
          return current;
        });
      });
    }

  };
}

;
//# sourceMappingURL=no-doubled-conjunction.js.map