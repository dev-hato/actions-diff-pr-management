{"version":3,"sources":["../src/no-doubled-joshi.ts"],"names":["createSurfaceKeyMap","tokens","filter","is助詞Token","reduce","keyMap","token","tokenKey","push","matchExceptionRule","pos_detail_1","surface_form","length","defaultOptions","min_interval","strict","allow","separatorCharacters","commaCharacters","report","context","options","helper","RuleHelper","minInterval","undefined","Error","isStrict","Syntax","RuleError","is読点Token","Paragraph","node","isChildNode","Link","Image","BlockQuote","Emphasis","isSentenceNode","type","SentenceSyntax","Sentence","txtParentNode","SeparatorParser","sentences","children","checkSentence","sentence","sentenceSource","StringSource","text","toString","concatTokens","countableTokens","joshiTokenSurfaceKeyMap","Object","keys","forEach","key","joshiName","indexOf","prev","current","startPosition","otherPosition","differenceIndex","originalIndex","originalIndexFromIndex","word_position","index","Promise","all","map"],"mappings":"AAAA;AACA;;;;;;;AACA;;AACA;;AACA;;AACA;;AAUA;;;;;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,mBAAT,CAA6BC,MAA7B,EAA4F;AACxF;AACA,SAAOA,MAAM,CAACC,MAAP,CAAcC,qBAAd,EAAyBC,MAAzB,CAAgC,CAACC,MAAD,EAASC,KAAT,KAAmB;AACtD;AACA,QAAMC,QAAQ,GAAG,kCAAiBD,KAAjB,CAAjB;;AACA,QAAI,CAACD,MAAM,CAACE,QAAD,CAAX,EAAuB;AACnBF,MAAAA,MAAM,CAACE,QAAD,CAAN,GAAmB,EAAnB;AACH;;AACDF,IAAAA,MAAM,CAACE,QAAD,CAAN,CAAiBC,IAAjB,CAAsBF,KAAtB;AACA,WAAOD,MAAP;AACH,GARM,EAQJ,EARI,CAAP;AASH;;AAED,SAASI,kBAAT,CAA4BR,MAA5B,EAAqD;AACjD,MAAMK,KAAK,GAAGL,MAAM,CAAC,CAAD,CAApB,CADiD,CAEjD;;AACA,MAAIK,KAAK,CAACI,YAAN,KAAuB,KAA3B,EAAkC;AAC9B,WAAO,IAAP;AACH,GALgD,CAMjD;;;AACA,MAAIJ,KAAK,CAACI,YAAN,KAAuB,KAAvB,IAAgCJ,KAAK,CAACK,YAAN,KAAuB,GAA3D,EAAgE;AAC5D,WAAO,IAAP;AACH,GATgD,CAUjD;;;AACA,MAAIL,KAAK,CAACI,YAAN,KAAuB,MAAvB,IAAiCJ,KAAK,CAACK,YAAN,KAAuB,GAA5D,EAAiE;AAC7D,WAAO,IAAP;AACH,GAbgD,CAcjD;AACA;;;AACA,MAAIV,MAAM,CAACW,MAAP,KAAkB,CAAlB,IAAuBX,MAAM,CAAC,CAAD,CAAN,CAAUS,YAAV,KAA2B,MAAlD,IAA4DT,MAAM,CAAC,CAAD,CAAN,CAAUS,YAAV,KAA2B,MAA3F,EAAmG;AAC/F,WAAO,IAAP;AACH;;AACD,SAAO,KAAP;AACH;AAED;AACA;AACA;;;AACA,IAAMG,cAAc,GAAG;AACnBC,EAAAA,YAAY,EAAE,CADK;AAEnBC,EAAAA,MAAM,EAAE,KAFW;AAGnBC,EAAAA,KAAK,EAAE,EAHY;AAInBC,EAAAA,mBAAmB,EAAE,CACjB,GADiB,EACZ;AACL,KAFiB,EAEZ;AACL,KAHiB,EAGZ;AACL,KAJiB,EAIZ;AACL,KALiB,EAKZ;AACL,KANiB,EAMZ;AACL,KAPiB,CAOZ;AAPY,GAJF;AAanBC,EAAAA,eAAe,EAAE,CACb,GADa,EAEb,GAFa,CAER;AAFQ;AAbE,CAAvB;;AA6CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAMC,MAAmC,GAAG,gBAAUC,OAAV,EAAiC;AAAA,MAAdC,OAAc,uEAAJ,EAAI;AACzE,MAAMC,MAAM,GAAG,IAAIC,8BAAJ,CAAeH,OAAf,CAAf,CADyE,CAEzE;;AACA,MAAMI,WAAW,GAAGH,OAAO,CAACP,YAAR,KAAyBW,SAAzB,GAAqCJ,OAAO,CAACP,YAA7C,GAA4DD,cAAc,CAACC,YAA/F;;AACA,MAAIU,WAAW,IAAI,CAAnB,EAAsB;AAClB,UAAM,IAAIE,KAAJ,CAAU,sCAAV,CAAN;AACH;;AACD,MAAMC,QAAQ,GAAGN,OAAO,CAACN,MAAR,IAAkBF,cAAc,CAACE,MAAlD;AACA,MAAMC,KAAK,GAAGK,OAAO,CAACL,KAAR,IAAiBH,cAAc,CAACG,KAA9C;AACA,MAAMC,mBAAmB,GAAGI,OAAO,CAACJ,mBAAR,IAA+BJ,cAAc,CAACI,mBAA1E;AACA,MAAMC,eAAe,GAAGG,OAAO,CAACH,eAAR,IAA2BL,cAAc,CAACK,eAAlE;AACA,MAAM;AAAEU,IAAAA,MAAF;AAAUT,IAAAA,MAAV;AAAkBU,IAAAA;AAAlB,MAAgCT,OAAtC;AACA,MAAMU,SAAS,GAAG,iCAAgBZ,eAAhB,CAAlB;AACA,SAAO;AACH,KAACU,MAAM,CAACG,SAAR,EAAmBC,IAAnB,EAAyB;AACrB,UAAIV,MAAM,CAACW,WAAP,CAAmBD,IAAnB,EAAyB,CAACJ,MAAM,CAACM,IAAR,EAAcN,MAAM,CAACO,KAArB,EAA4BP,MAAM,CAACQ,UAAnC,EAA+CR,MAAM,CAACS,QAAtD,CAAzB,CAAJ,EAA+F;AAC3F;AACH;;AACD,UAAMC,cAAc,GAAIN,IAAD,IAAyC;AAC5D,eAAOA,IAAI,CAACO,IAAL,KAAcC,yBAAeC,QAApC;AACH,OAFD;;AAGA,UAAMC,aAAa,GAAG,gCAAeV,IAAf,EAAqB;AACvCW,QAAAA,eAAe,EAAE;AACb1B,UAAAA;AADa;AADsB,OAArB,CAAtB;AAKA,UAAM2B,SAAS,GAAGF,aAAa,CAACG,QAAd,CAAuB3C,MAAvB,CAA8BoC,cAA9B,CAAlB;;AACA,UAAMQ,aAAa;AAAA,qCAAG,WAAOC,QAAP,EAAkC;AACpD,cAAMC,cAAc,GAAG,IAAIC,kCAAJ,CAAiBF,QAAjB,CAAvB;AACA,cAAMG,IAAI,GAAGF,cAAc,CAACG,QAAf,EAAb;AACA,cAAMlD,MAAM,SAAS,yBAASiD,IAAT,CAArB,CAHoD,CAIpD;AACA;AACA;AACA;;AACA,cAAME,YAAY,GAAG,oCAAmBnD,MAAnB,CAArB;AACA,cAAMoD,eAAe,GAAGD,YAAY,CAAClD,MAAb,CAAqBI,KAAD,IAAW;AACnD,gBAAIqB,QAAJ,EAAc;AACV,qBAAO,2BAAUrB,KAAV,CAAP;AACH,aAHkD,CAInD;AACA;AACA;;;AACA,gBAAI,2BAAUA,KAAV,CAAJ,EAAsB;AAClB,qBAAO,IAAP;AACH,aATkD,CAUnD;AACA;;;AACA,gBAAIwB,SAAS,CAACxB,KAAD,CAAb,EAAsB;AAClB,qBAAO,IAAP;AACH,aAdkD,CAenD;;;AACA,mBAAO,2BAAUA,KAAV,CAAP;AACH,WAjBuB,CAAxB;AAkBA,cAAMgD,uBAAuB,GAAGtD,mBAAmB,CAACqD,eAAD,CAAnD;AACA;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEgBE,UAAAA,MAAM,CAACC,IAAP,CAAYF,uBAAZ,EAAqCG,OAArC,CAA8CC,GAAD,IAAS;AAClD,gBAAMzD,MAAuB,GAAGqD,uBAAuB,CAACI,GAAD,CAAvD;AACA,gBAAMC,SAAS,GAAG,yCAAwBD,GAAxB,CAAlB,CAFkD,CAGlD;;AACA,gBAAI1C,KAAK,CAAC4C,OAAN,CAAcD,SAAd,KAA4B,CAAhC,EAAmC;AAC/B;AACH,aANiD,CAOlD;;;AACA,gBAAI,CAAChC,QAAL,EAAe;AACX,kBAAIlB,kBAAkB,CAACR,MAAD,CAAtB,EAAgC;AAC5B;AACH;AACJ;;AACD,gBAAIA,MAAM,CAACW,MAAP,IAAiB,CAArB,EAAwB;AACpB,qBADoB,CACZ;AACX,aAfiD,CAgBlD;AACA;;;AACAX,YAAAA,MAAM,CAACG,MAAP,CAAc,CAACyD,IAAD,EAAOC,OAAP,KAAmB;AAC7B,kBAAMC,aAAa,GAAGV,eAAe,CAACO,OAAhB,CAAwBC,IAAxB,CAAtB;AACA,kBAAMG,aAAa,GAAGX,eAAe,CAACO,OAAhB,CAAwBE,OAAxB,CAAtB,CAF6B,CAG7B;;AACA,kBAAMG,eAAe,GAAGD,aAAa,GAAGD,aAAxC;;AACA,kBAAIE,eAAe,IAAIzC,WAAvB,EAAoC;AAChC;AACA,oBAAM0C,aAAa,GAAGlB,cAAc,CAACmB,sBAAf,CAAsCL,OAAO,CAACM,aAAR,GAAwB,CAA9D,CAAtB;AACAjD,gBAAAA,MAAM,CACF4B,QADE,EAEF,IAAIlB,SAAJ,8GACyB8B,SADzB,gEAEI;AACIU,kBAAAA,KAAK,EAAEH;AADX,iBAFJ,CAFE,CAAN;AASH;;AACD,qBAAOJ,OAAP;AACH,aAnBD;AAoBH,WAtCD;AAuCH,SA5EkB;;AAAA,wBAAbhB,aAAa;AAAA;AAAA;AAAA,SAAnB;;AA6EA,aAAOwB,OAAO,CAACC,GAAR,CAAY3B,SAAS,CAAC4B,GAAV,CAAc1B,aAAd,CAAZ,CAAP;AACH;;AA5FE,GAAP;AA8FH,CA3GD;;eA4Ge3B,M","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport { RuleHelper } from \"textlint-rule-helper\";\nimport { splitAST as splitSentences, Syntax as SentenceSyntax, SentenceNode } from \"sentence-splitter\";\nimport { tokenize, KuromojiToken } from \"kuromojin\";\nimport {\n    is助詞Token,\n    create読点Matcher,\n    concatJoishiTokens,\n    createKeyFromKey,\n    restoreToSurfaceFromKey,\n    is括弧Token,\n} from \"./token-utils\";\nimport { TxtNode } from \"@textlint/ast-node-types\";\nimport { TextlintRuleModule } from \"@textlint/types\";\nimport { StringSource } from \"textlint-util-to-string\";\n\n/**\n * Create token map object\n * {\n *  \"は:助詞.係助詞\": [token, token]\n * }\n * @param tokens\n * @returns {*}\n */\nfunction createSurfaceKeyMap(tokens: KuromojiToken[]): { [index: string]: KuromojiToken[] } {\n    // 助詞のみを対象とする\n    return tokens.filter(is助詞Token).reduce((keyMap, token) => {\n        // \"は:助詞.係助詞\" : [token]\n        const tokenKey = createKeyFromKey(token);\n        if (!keyMap[tokenKey]) {\n            keyMap[tokenKey] = [];\n        }\n        keyMap[tokenKey].push(token);\n        return keyMap;\n    }, {} as { [index: string]: KuromojiToken[] });\n}\n\nfunction matchExceptionRule(tokens: KuromojiToken[]) {\n    const token = tokens[0];\n    // \"の\" の重なりは例外\n    if (token.pos_detail_1 === \"連体化\") {\n        return true;\n    }\n    // \"を\" の重なりは例外\n    if (token.pos_detail_1 === \"格助詞\" && token.surface_form === \"を\") {\n        return true;\n    }\n    // 接続助詞 \"て\" の重なりは例外\n    if (token.pos_detail_1 === \"接続助詞\" && token.surface_form === \"て\") {\n        return true;\n    }\n    // 並立助詞は例外\n    // 登ったり降りたり\n    if (tokens.length === 2 && tokens[0].pos_detail_1 === \"並立助詞\" && tokens[1].pos_detail_1 === \"並立助詞\") {\n        return true;\n    }\n    return false;\n}\n\n/*\n default options\n */\nconst defaultOptions = {\n    min_interval: 1,\n    strict: false,\n    allow: [],\n    separatorCharacters: [\n        \".\", // period\n        \"．\", // (ja) zenkaku-period\n        \"。\", // (ja) 句点\n        \"?\", // question mark\n        \"!\", //  exclamation mark\n        \"？\", // (ja) zenkaku question mark\n        \"！\", // (ja) zenkaku exclamation mark\n    ],\n    commaCharacters: [\n        \"、\",\n        \"，\", // 全角カンマ\n    ],\n};\n\nexport interface Options {\n    /**\n     * 助詞の最低間隔値\n     * 指定した間隔値以下で同じ助詞が出現した場合エラーが出力されます\n     */\n    min_interval?: number;\n    /**\n     * デフォルトの例外パターンもエラーにするかどうか\n     * デフォルト: false\n     */\n    strict?: boolean;\n    /**\n     * 複数回の出現を許す助詞の配列\n     * 例): [\"も\", \"や\"]\n     */\n    allow?: string[];\n    /**\n     * 文の区切りとなる文字(句点)の配列\n     */\n    separatorCharacters?: string[];\n    /**\n     * 読点となる文字の配列\n     */\n    commaCharacters?: string[];\n}\n\n/*\n 1. Paragraph Node -> text\n 2. text -> sentences\n 3. tokenize sentence\n 4. report error if found word that match the rule.\n\n TODO: need abstraction\n */\nconst report: TextlintRuleModule<Options> = function (context, options = {}) {\n    const helper = new RuleHelper(context);\n    // 最低間隔値\n    const minInterval = options.min_interval !== undefined ? options.min_interval : defaultOptions.min_interval;\n    if (minInterval <= 0) {\n        throw new Error(\"options.min_intervalは1以上の数値を指定してください\");\n    }\n    const isStrict = options.strict || defaultOptions.strict;\n    const allow = options.allow || defaultOptions.allow;\n    const separatorCharacters = options.separatorCharacters || defaultOptions.separatorCharacters;\n    const commaCharacters = options.commaCharacters || defaultOptions.commaCharacters;\n    const { Syntax, report, RuleError } = context;\n    const is読点Token = create読点Matcher(commaCharacters);\n    return {\n        [Syntax.Paragraph](node) {\n            if (helper.isChildNode(node, [Syntax.Link, Syntax.Image, Syntax.BlockQuote, Syntax.Emphasis])) {\n                return;\n            }\n            const isSentenceNode = (node: TxtNode): node is SentenceNode => {\n                return node.type === SentenceSyntax.Sentence;\n            };\n            const txtParentNode = splitSentences(node, {\n                SeparatorParser: {\n                    separatorCharacters,\n                },\n            });\n            const sentences = txtParentNode.children.filter(isSentenceNode);\n            const checkSentence = async (sentence: SentenceNode) => {\n                const sentenceSource = new StringSource(sentence);\n                const text = sentenceSource.toString();\n                const tokens = await tokenize(text);\n                // 助詞 + 助詞は 一つの助詞として扱う\n                // https://github.com/textlint-ja/textlint-rule-no-doubled-joshi/issues/15\n                // 連語(助詞)の対応\n                // http://www.weblio.jp/parts-of-speech/%E9%80%A3%E8%AA%9E(%E5%8A%A9%E8%A9%9E)_1\n                const concatTokens = concatJoishiTokens(tokens);\n                const countableTokens = concatTokens.filter((token) => {\n                    if (isStrict) {\n                        return is助詞Token(token);\n                    }\n                    // \"(\"や\")\"などもトークンとしてカウントする\n                    // xxxx（xxx) xxx でカッコの中と外に距離を一つ増やす目的\n                    // https://github.com/textlint-ja/textlint-rule-no-doubled-joshi/issues/31\n                    if (is括弧Token(token)) {\n                        return true;\n                    }\n                    // \"、\" があると助詞同士の距離が開くようにすることで、並列的な\"、\"の使い方を許容する目的\n                    // https://github.com/azu/textlint-rule-no-doubled-joshi/issues/2\n                    if (is読点Token(token)) {\n                        return true;\n                    }\n                    // デフォルトでは、\"、\"を間隔値の距離としてカウントする\n                    return is助詞Token(token);\n                });\n                const joshiTokenSurfaceKeyMap = createSurfaceKeyMap(countableTokens);\n                /*\n                    # Data Structure\n\n                    joshiTokens = [tokenA, tokenB, tokenC, tokenD, tokenE, tokenF]\n                    joshiTokenSurfaceKeyMap = {\n                        \"は:助詞.係助詞\": [tokenA, tokenC, tokenE],\n                        \"で:助詞.係助詞\": [tokenB, tokenD, tokenF]\n                    }\n                    */\n                Object.keys(joshiTokenSurfaceKeyMap).forEach((key) => {\n                    const tokens: KuromojiToken[] = joshiTokenSurfaceKeyMap[key];\n                    const joshiName = restoreToSurfaceFromKey(key);\n                    // check allow\n                    if (allow.indexOf(joshiName) >= 0) {\n                        return;\n                    }\n                    // strict mode ではない時例外を除去する\n                    if (!isStrict) {\n                        if (matchExceptionRule(tokens)) {\n                            return;\n                        }\n                    }\n                    if (tokens.length <= 1) {\n                        return; // no duplicated token\n                    }\n                    // if found differenceIndex less than\n                    // tokes are sorted ascending order\n                    tokens.reduce((prev, current) => {\n                        const startPosition = countableTokens.indexOf(prev);\n                        const otherPosition = countableTokens.indexOf(current);\n                        // 助詞token同士の距離が設定値以下ならエラーを報告する\n                        const differenceIndex = otherPosition - startPosition;\n                        if (differenceIndex <= minInterval) {\n                            // padding positionを計算する\n                            const originalIndex = sentenceSource.originalIndexFromIndex(current.word_position - 1);\n                            report(\n                                sentence,\n                                new RuleError(\n                                    `一文に二回以上利用されている助詞 \"${joshiName}\" がみつかりました。`,\n                                    {\n                                        index: originalIndex,\n                                    }\n                                )\n                            );\n                        }\n                        return current;\n                    });\n                });\n            };\n            return Promise.all(sentences.map(checkSentence));\n        },\n    };\n};\nexport default report;\n"],"file":"no-doubled-joshi.js"}